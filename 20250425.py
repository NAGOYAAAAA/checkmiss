import sys
import subprocess
import importlib
from pathlib import Path


def check_version(lib_name):
    package_to_module = {
        'python-dateutil': 'dateutil',
        'pandas': 'pandas',
        'chardet': 'chardet',
        'tqdm': 'tqdm',
        'requests': 'requests'
    }
    module_name = package_to_module.get(lib_name, lib_name)
    try:
        module = importlib.import_module(module_name)
        return module.__version__
    except ModuleNotFoundError:
        return None


def install_from_source(lib, source):
    subprocess.run(
        [sys.executable, "-m", "pip", "install", "-i", source, lib],
        check=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        text=True
    )


def install_libraries(libs):
    sources = [
        "https://pypi.tuna.tsinghua.edu.cn/simple",
        "https://mirrors.nankai.edu.cn/pypi/web/simple",
        "https://mirrors.aliyun.com/pypi/simple/"
    ]

    if 'tqdm' not in libs:
        libs = ['tqdm'] + libs

    python_version = f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}"
    print(f"""===============================================
[ç³»ç»Ÿä¿¡æ¯] Python ç‰ˆæœ¬ï¼š{python_version}
===============================================""")
    print("[ä¾èµ–æ£€æŸ¥] å¼€å§‹æ£€æµ‹æ‰€éœ€åº“...\n")

    successful_source = None
    if check_version('tqdm') is None:
        for source in sources:
            print(f"[å°è¯•å®‰è£…tqdm] å½“å‰æºï¼š{source}")
            try:
                install_from_source('tqdm', source)
                successful_source = source
                print("[å®‰è£…æˆåŠŸ] tqdmå·²å®‰è£…")
                break
            except subprocess.CalledProcessError as e:
                print(f"[å®‰è£…å¤±è´¥] {e.stdout}")
        else:
            print("[è‡´å‘½é”™è¯¯] æ‰€æœ‰æºå‡æ— æ³•å®‰è£…tqdmï¼Œè¯·æ‰‹åŠ¨å®‰è£…åé‡å¯ç¨‹åº")
            input("æŒ‰ä»»æ„é”®é€€å‡º...")
            sys.exit(1)

    # é”å®š urllib3 ç‰ˆæœ¬ä¸º 1.x ç³»åˆ—
    if 'requests' in libs:
        libs.append('urllib3<2.0')

    installed = {lib: check_version(lib) for lib in libs}
    missing = [lib for lib in libs if installed[lib] is None]

    if not missing:
        print("[ä¾èµ–çŠ¶æ€] æ‰€æœ‰åº“å·²å®‰è£…ï¼š")
        key_dependencies = ['pandas', 'python-dateutil', 'chardet', 'requests']
        for lib in key_dependencies:
            print(f" - {lib}: {installed[lib]}")
        return True

    print(f"[éœ€è¦å®‰è£…] ä»¥ä¸‹åº“æœªæ‰¾åˆ°ï¼š{', '.join(missing)}")
    confirm = input("æ˜¯å¦ç»§ç»­å®‰è£…ï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("[ç”¨æˆ·å–æ¶ˆ] å®‰è£…å·²å–æ¶ˆï¼Œç¨‹åºé€€å‡º")
        return False

    print("\n[å¼€å§‹å®‰è£…] è‡ªåŠ¨åˆ‡æ¢é•œåƒæºå°è¯•å®‰è£…...")
    from tqdm import tqdm
    for lib in tqdm(missing, desc="å®‰è£…è¿›åº¦", unit="åº“", dynamic_ncols=True):
        if successful_source:
            try:
                print(f"\n[å®‰è£…{lib}] å½“å‰æºï¼š{successful_source}")
                install_from_source(lib, successful_source)
                installed[lib] = check_version(lib)
                print(f"[å®‰è£…æˆåŠŸ] {lib} ç‰ˆæœ¬ï¼š{installed[lib]}")
                continue
            except subprocess.CalledProcessError as e:
                print(f"[å®‰è£…å¤±è´¥] {e.stdout}")
        for source in sources:
            print(f"\n[å®‰è£…{lib}] å½“å‰æºï¼š{source}")
            try:
                install_from_source(lib, source)
                successful_source = source
                installed[lib] = check_version(lib)
                print(f"[å®‰è£…æˆåŠŸ] {lib} ç‰ˆæœ¬ï¼š{installed[lib]}")
                break
            except subprocess.CalledProcessError as e:
                print(f"[å®‰è£…å¤±è´¥] {e.stdout}")
        else:
            print(f"[ä¸¥é‡é”™è¯¯] {lib} å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…ï¼špip install {lib}")
            input("æŒ‰ä»»æ„é”®é€€å‡º...")
            sys.exit(1)

    print("\n[ä¾èµ–çŠ¶æ€] å®‰è£…å®Œæˆï¼š")
    key_dependencies = ['pandas', 'python-dateutil', 'chardet', 'requests']
    for lib in key_dependencies:
        print(f" - {lib}: {installed[lib]}")
    return True


if __name__ == "__main__":
    required_libs = ['pandas', 'chardet', 'python-dateutil', 'requests', 'tqdm']
    if not install_libraries(required_libs):
        input("\n[å®‰è£…å¤±è´¥] æŒ‰ä»»æ„é”®é€€å‡ºç¨‹åº...")
        sys.exit(1)

    import traceback
    import re
    import pandas as pd
    import chardet
    from dateutil.parser import parse
    from tqdm import tqdm
    import os
    import datetime
    import requests

    COLUMN_MAPPING = {
        'clinic': {
            'name': 'å§“å',
            'id': 'èº«ä»½è¯',
            'diagnosis': 'è¯Šæ–­',
            'visit_time': 'å°±è¯Šæ—¶é—´'
        },
        'report': {
            'name': 'æ‚£è€…å§“å',
            'id': 'æœ‰æ•ˆè¯ä»¶å·',
            'disease': 'ç–¾ç—…åç§°',
            'report_time': 'æŠ¥å‘Šå¡å½•å…¥æ—¶é—´'
        }
    }


    def clean_date(date_str):
        try:
            date_obj = parse(date_str, dayfirst=False, yearfirst=True)
            if date_obj.time() == pd.Timestamp('00:00:00').time():
                return date_obj.strftime('%Y-%m-%d')
            else:
                return date_obj.strftime('%Y-%m-%d %H:%M:%S')
        except Exception as e:
            if not hasattr(clean_date, 'error_samples'):
                clean_date.error_samples = []
            if len(clean_date.error_samples) < 5:
                clean_date.error_samples.append(date_str)
            return pd.NaT


    def read_data(data_path):
        raw_data = b''
        try:
            with tqdm(total=os.path.getsize(data_path), desc="è¯»å–æ–‡ä»¶", unit='B') as pbar:
                with open(data_path, 'rb') as f:
                    chunk = f.read(1024 * 1024)
                    while chunk:
                        raw_data += chunk
                        pbar.update(len(chunk))
                        chunk = f.read(1024 * 1024)
            result = chardet.detect(raw_data)
            if result['encoding'] in ['GB2312', 'GB18030']:
                encoding = 'GBK'
            else:
                encoding = result['encoding'] or 'GBK'
            if encoding == 'UTF-8-SIG':
                encoding = 'utf-8'
            data = pd.read_csv(data_path, sep=',', encoding=encoding)
        except Exception as e:
            for enc in ['GBK', 'GB18030', 'utf-8']:
                try:
                    data = pd.read_csv(data_path, sep=',', encoding=enc)
                    print(f"æˆåŠŸä½¿ç”¨{enc}ç¼–ç è¯»å–æ–‡ä»¶")
                    break
                except:
                    continue

        data.columns = data.columns.str.strip()
        for col in data.columns:
            if data[col].dtype != 'object':
                data[col] = data[col].astype(str)
        data.fillna("æ— ", inplace=True)
        for time_col in [COLUMN_MAPPING['clinic']['visit_time'], COLUMN_MAPPING['report']['report_time']]:
            if time_col in data.columns:
                data[time_col] = data[time_col].apply(clean_date)
                invalid_count = data[time_col].isna().sum()
                if invalid_count > 0:
                    print(f"[æ ¼å¼è­¦å‘Š] {data_path.name}çš„{time_col}åˆ—å­˜åœ¨{invalid_count}æ¡æ— æ•ˆæ—¥æœŸï¼Œå·²å°½åŠ›æ¸…æ´—ï¼Œä»æœ‰æ— æ•ˆæ•°æ®ã€‚")
                    if hasattr(clean_date, 'error_samples'):
                        print(f"æ— æ³•è§£æçš„æ—¥æœŸç¤ºä¾‹ï¼š{clean_date.error_samples}")
        return data


    def select_data(data, output_file):
        required_cols = {COLUMN_MAPPING['clinic']['visit_time'], COLUMN_MAPPING['clinic']['diagnosis']}
        missing_cols = required_cols - set(data.columns)
        if missing_cols:
            raise ValueError(
                f"ç¼ºå°‘å…³é”®åˆ—ï¼š{missing_cols}\n"
                f"å½“å‰æ–‡ä»¶åŒ…å«çš„åˆ—ï¼š{list(data.columns)}\n"
                "è¯·æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ç¬¦åˆæ ¼å¼è¦æ±‚ï¼š\n"
                "1. ä½¿ç”¨æ­£ç¡®çš„CSVæ ¼å¼\n"
                "2. åˆ—ååŒ…å«ä¸­æ–‡æ ‡ç‚¹ç¬¦å·\n"
                "3. æ–‡ä»¶ç¼–ç ä¸ºUTF-8æˆ–GBK"
            )

        print(f"åŸå§‹æ•°æ®ï¼š{len(data)}æ¡ï¼Œå¼€å§‹æ¸…æ´—è¯Šæ–­åˆ—...")
        data[COLUMN_MAPPING['clinic']['diagnosis']] = data[COLUMN_MAPPING['clinic']['diagnosis']].astype(
            str).str.replace(r'\s+', '', regex=True)
        print("âœ… è¯Šæ–­åˆ—ç©ºæ ¼æ¸…ç†å®Œæˆ")
        inf_pattern = re.compile(r"""
            æ–°å† |æ–°å‹å† çŠ¶|é¼ ç–«|éœä¹±|ç—…æ¯’æ€§è‚ç‚|ä¹™è‚|ä¸™è‚|ä¸è‚|æˆŠè‚|è„Šç°|è„Šé«“ç°è´¨ç‚|ç¦½æµæ„Ÿ|éº»ç–¹|å‡ºè¡€çƒ­|ç‹‚çŠ¬ç—…|è„‘ç‚|ç™»é©çƒ­|ç‚­ç–½|ç—¢ç–¾|èŒç—¢|å¿—è´ºæ°èŒ|ç»“æ ¸|ä¹™å‹|ç”²å‹|ä¸™å‹|ä¼ æŸ“æ€§|ä¼¤å¯’|æµè„‘|æµè¡Œæ€§è„‘è„Šé«“ç‚|ç™¾æ—¥å’³|ç™½å–‰|æ–°ç ´|æ–°ç”Ÿå„¿ç ´ä¼¤é£|çŒ©çº¢çƒ­|çŒ© çº¢ çƒ­|å¸ƒé²æ°èŒ|å¸ƒç—…|æ·‹ç—…|æ¢…æ¯’|é’©ä½“ç—…|é’©ç«¯èºæ—‹ä½“ç—…|è¡€å¸è™«ç—…|ç–Ÿç–¾|AIDS|è‰¾æ»‹ç—…|HIV|æµè¡Œæ€§æ„Ÿå†’|æµæ„Ÿ|æµè…®|æµè¡Œæ€§è…®è…ºç‚|é£ç–¹|å‡ºè¡€æ€§ç»“è†œç‚|éº»é£|é»‘çƒ­ç—…|åŒ…è™«|æ‰‹è¶³å£|ä¸è™«|æ„ŸæŸ“æ€§è…¹æ³»|è½®çŠ¶ç—…æ¯’|ç»†èŒ|ç—…æ¯’|ç—…æ¯’æ€§è…¹æ³»|ç»†èŒæ€§è…¹æ³»|ä¹™è„‘|æ°´ç—˜|è‚ç‚|å…¶å®ƒæ„ŸæŸ“æ€§è…¹æ³»ç—…|æµè¡Œæ€§æ„Ÿå†’
        """, re.VERBOSE | re.UNICODE)
        data_selected = data[data[COLUMN_MAPPING['clinic']['diagnosis']].str.contains(inf_pattern, na=False)]
        exclude_pattern = re.compile(r"""
            é™ˆæ—§|ç­›æŸ¥|ç–±ç–¹ç—…æ¯’|è§’è†œç‚|è¨éº»ç–¹|æºå¸¦è€…|EBç—…æ¯’|ç»†èŒæ€§é˜´é“|ä¼ æŸ“æ€§å•æ ¸ç»†èƒ|äººä¹³å¤´ç˜¤ç—…æ¯’|ä¼ æŸ“æ€§è½¯ç–£|å¼€è¯|å‘¼å¸é“.*?ç»†èŒæ„ŸæŸ“|ç–±ç–¹æ€§å’½å³¡ç‚|å–è¯|æ‹¿è¯|é¼»çª¦ç‚.*?ç»†èŒ|ç—…æ¯’ç–£|ä¹³å¤´ç˜¤
        """, re.VERBOSE | re.DOTALL | re.UNICODE)
        data_selected = data_selected[
            ~data_selected[COLUMN_MAPPING['clinic']['diagnosis']].str.contains(exclude_pattern, na=False)]

        print(f"ğŸ” ç­›é€‰ç»“æœï¼š{len(data_selected)}æ¡æœ‰æ•ˆè®°å½•")
        if COLUMN_MAPPING['clinic']['visit_time'] not in data_selected.columns:
            raise ValueError(f"ç­›é€‰åæ•°æ®ç¼ºå°‘ã€{COLUMN_MAPPING['clinic']['visit_time']}ã€åˆ—")

        data_selected = data_selected.sort_values(COLUMN_MAPPING['clinic']['visit_time']).reset_index(drop=True)
        data_selected = data_selected.loc[:, ~data_selected.columns.str.contains('^Unnamed')]
        data_selected.to_csv(output_file, index=False, encoding='utf-8')
        print(f"âœ… æ­¥éª¤1å®Œæˆï¼šåˆç­›ç»“æœä¿å­˜è‡³ {output_file.resolve()}")


    def match_two_database(data_path1, data_path2):
        data1 = read_data(data_path1)
        data2 = read_data(data_path2)
        data1[COLUMN_MAPPING['clinic']['id']] = (data1[COLUMN_MAPPING['clinic']['id']].astype(str)
                                                 .str.replace(r'\.0$', '', regex=True).str.replace(
            r'[^\dA-Za-z]', '', regex=True).str.upper())
        data1[COLUMN_MAPPING['clinic']['name']] = data1[COLUMN_MAPPING['clinic']['name']].str.strip().str.replace(
            r'\s+', '', regex=True).str.upper()
        data2[COLUMN_MAPPING['report']['id']] = (data2[COLUMN_MAPPING['report']['id']].astype(str)
                                                 .str.replace(r'\.0$', '', regex=True).str.replace(
            r'[^\dA-Za-zå·]', '', regex=True).str.replace(r'å·', '', regex=True).str.upper())
        data2[COLUMN_MAPPING['report']['name']] = data2[COLUMN_MAPPING['report']['name']].str.strip().str.replace(
            r'\s+', '', regex=True).str.upper()
        merge_keys = {'é—¨è¯Šæ—¥å¿—': [COLUMN_MAPPING['clinic']['id'], COLUMN_MAPPING['clinic']['name']],
                      'ç½‘æŠ¥å¡': [COLUMN_MAPPING['report']['id'], COLUMN_MAPPING['report']['name']]}
        for df, cols in merge_keys.items():
            if not all(col in data1.columns if df == 'é—¨è¯Šæ—¥å¿—' else col in data2.columns for col in cols):
                print(f"âŒ é”™è¯¯ï¼š{df} ç¼ºå°‘åˆå¹¶åˆ— {cols}")
                return None
        data2 = data2[[COLUMN_MAPPING['report']['name'], COLUMN_MAPPING['report']['report_time'],
                       COLUMN_MAPPING['report']['disease'], COLUMN_MAPPING['report']['id']]].sort_values(
            COLUMN_MAPPING['report']['report_time']).reset_index(drop=True)
        data_match = data1.merge(data2, how='left', left_on=merge_keys['é—¨è¯Šæ—¥å¿—'], right_on=merge_keys['ç½‘æŠ¥å¡'])
        data_match = data_match.loc[:, ~data_match.columns.str.contains('^Unnamed')]
        return data_match


    def analysis(data_match, export_txt, export_reported, export_missing, export_duplicate, time_unit):
        if {COLUMN_MAPPING['report']['report_time'], COLUMN_MAPPING['clinic']['visit_time']}.difference(
                data_match.columns):
            print("âŒ é”™è¯¯ï¼šåˆå¹¶æ•°æ®ç¼ºå°‘å¿…è¦æ—¶é—´åˆ—")
            return

        not_reported = data_match[data_match[COLUMN_MAPPING['report']['report_time']].isna()].reset_index(drop=True)
        reported = data_match[data_match[COLUMN_MAPPING['report']['report_time']].notna()].reset_index(drop=True)
        reported[[COLUMN_MAPPING['report']['report_time'], COLUMN_MAPPING['clinic']['visit_time']]] = reported[
            [COLUMN_MAPPING['report']['report_time'], COLUMN_MAPPING['clinic']['visit_time']]].apply(pd.to_datetime,
                                                                                                     errors='coerce')
        valid_time_count = reported[
            [COLUMN_MAPPING['report']['report_time'], COLUMN_MAPPING['clinic']['visit_time']]].notna().all(axis=1).sum()
        if valid_time_count == 0:
            print("âš ï¸ è­¦å‘Šï¼šæ— æœ‰æ•ˆæŠ¥å¡æ•°æ®ï¼Œæ— æ³•å®Œæˆæ—¶é—´åˆ†æã€‚è¯·æ£€æŸ¥æ—¶é—´åˆ—æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
            return

        reported = reported.dropna(
            subset=[COLUMN_MAPPING['report']['report_time'], COLUMN_MAPPING['clinic']['visit_time']]).reset_index(
            drop=True)
        dup_cols = [COLUMN_MAPPING['clinic']['name'], COLUMN_MAPPING['clinic']['id'], COLUMN_MAPPING['report']['disease'],
                    COLUMN_MAPPING['clinic']['visit_time']]
        duplicates = data_match[data_match.duplicated(subset=dup_cols, keep=False)]
        duplicate_count = len(duplicates)
        if duplicate_count > 0:
            if 'æ—¶é—´é—´éš”' in duplicates.columns:
                dup_cols.append('æ—¶é—´é—´éš”')
            duplicates[dup_cols].to_csv(export_duplicate, index=False, encoding='utf-8')
            print(f"âš ï¸ å‘ç°{duplicate_count}æ¡é‡å¤æ¡ç›®ï¼Œå·²ä¿å­˜è‡³ {export_duplicate.resolve()}")
        time_delta = reported[COLUMN_MAPPING['report']['report_time']] - reported[
            COLUMN_MAPPING['clinic']['visit_time']]
        negative_delta = (reported[COLUMN_MAPPING['report']['report_time']] < reported[
            COLUMN_MAPPING['clinic']['visit_time']]).sum()
        if negative_delta > 0:
            print(f"è­¦å‘Šï¼šå‘ç°{negative_delta}æ¡è®°å½•æŠ¥å‘Šæ—¶é—´æ—©äºå°±è¯Šæ—¶é—´ï¼Œè¯·æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§ï¼")
        if time_unit == 'd':
            reported['æ—¶é—´é—´éš”'] = time_delta.dt.days
        else:
            reported['æ—¶é—´é—´éš”'] = time_delta.dt.total_seconds() // 3600
        target_cols = [COLUMN_MAPPING['clinic']['name'], COLUMN_MAPPING['clinic']['id'],
                       COLUMN_MAPPING['clinic']['diagnosis'], COLUMN_MAPPING['clinic']['visit_time'],
                       COLUMN_MAPPING['report']['name'], COLUMN_MAPPING['report']['id'],
                       COLUMN_MAPPING['report']['disease'], COLUMN_MAPPING['report']['report_time'], 'æ—¶é—´é—´éš”']
        reported = reported[target_cols] if 'æ—¶é—´é—´éš”' in reported.columns else reported[target_cols[:-1]]
        reported.to_csv(export_reported, index=False, encoding='utf-8')
        not_reported.to_csv(export_missing, index=False, encoding='utf-8')
        timely = (reported['æ—¶é—´é—´éš”'] <= (2 if time_unit == 'd' else 48)).sum()
        timely_rate = timely / len(reported) if len(reported) else 0
        report = (
            f"ã€æŠ¥å¡åŠæ—¶æ€§åˆ†æã€‘\n"
            f"æ€»ç—…ä¾‹ï¼š{len(data_match)} | æœªæŠ¥å¡ï¼š{len(not_reported)}({len(not_reported)/len(data_match):.2%})\n"
            f"å·²æŠ¥å¡ï¼š{len(reported)} | åŠæ—¶æŠ¥å¡ï¼ˆâ‰¤{'2å¤©' if time_unit == 'd' else '48å°æ—¶'}ï¼‰ï¼š{timely} | åŠæ—¶ç‡ï¼š{timely_rate:.2%}\n"
            f"å·²æŠ¥å¡æ–‡ä»¶ä¸­çš„é‡å¤æ¡ç›®ï¼š{duplicate_count} æ¡ï¼ˆå§“å+èº«ä»½è¯+ç–¾ç—…åç§°+å°±è¯Šæ—¶é—´é‡å¤ï¼‰*æ³¨æ„å¯¹åŠæ—¶ç‡çš„å½±å“"
        )
        if negative_delta > 0:
            report += f"\nè­¦å‘Šï¼šå‘ç°{negative_delta}æ¡è®°å½•æŠ¥å‘Šæ—¶é—´æ—©äºå°±è¯Šæ—¶é—´ï¼Œè¯·æ£€æŸ¥æ•°æ®å‡†ç¡®æ€§ï¼"
        with open(export_txt, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"âœ… æ­¥éª¤2å®Œæˆï¼šåˆ†ææŠ¥å‘Šä¿å­˜è‡³ {export_txt.resolve()}")


    def show_instructions():
        doc = """
        


        >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
        ã€ä¼ æŸ“ç—…æŠ¥å¡åˆ†æç³»ç»Ÿä½¿ç”¨è¯´æ˜ã€‘
        versionï¼šV20250417    authorï¼šYueXiuCDC-LGY    
        åŠŸèƒ½ï¼šè‡ªåŠ¨ç­›é€‰ä¼ æŸ“ç—…é—¨è¯Šæ•°æ®å¹¶åˆ†ææŠ¥å¡åŠæ—¶æ€§
        ç³»ç»Ÿæ”¯æŒï¼šWindowsï¼ŒMacOsï¼ŒLinux
        â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” 
        å·²æµ‹è¯•é€šè¿‡Pythonç‰ˆæœ¬ï¼š[3.7.3],[3.9.6],[3.13.3]
        â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” 
        â–¶ æ“ä½œæ­¥éª¤ï¼š
        1. å‡†å¤‡æ–‡ä»¶ï¼š
           - åŒ»é™¢é—¨è¯Šæ—¥å¿—.csvï¼ˆå¿…é¡»åˆ—ï¼šå§“åã€èº«ä»½è¯ã€è¯Šæ–­ã€å°±è¯Šæ—¶é—´ï¼‰
           - å¤§ç–«æƒ…ç½‘æŠ¥å¡.csvï¼ˆå¿…é¡»åˆ—ï¼šæ‚£è€…å§“åã€æœ‰æ•ˆè¯ä»¶å·ã€ç–¾ç—…åç§°ã€æŠ¥å‘Šå¡å½•å…¥æ—¶é—´ï¼‰

        2. æ”¾ç½®åŒä¸€æ–‡ä»¶å¤¹ä¸‹ï¼š
           æ–‡ä»¶å¤¹
           - åŒ»é™¢é—¨è¯Šæ—¥å¿—.csv
           - å¤§ç–«æƒ…ç½‘æŠ¥å¡.csv
           - [æœ¬ç¨‹åº].py

        3. è¿è¡Œç¨‹åºæŒ‰æ­¥éª¤æ‰§è¡Œ
        â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€” 
        â–¶ æ³¨æ„äº‹é¡¹ï¼š
        âœ… æŸ¥çœ‹Pythonç‰ˆæœ¬æ˜¯å¦ä¸ºå·²æµ‹è¯•é€šè¿‡ç‰ˆæœ¬
        âœ… æ–‡ä»¶è·¯å¾„ä¸èƒ½åŒ…å«ä¸­æ–‡/ç‰¹æ®Šç¬¦å·
        âœ… å¿…é¡»ä½¿ç”¨æŒ‡å®šæ–‡ä»¶åï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰
        âœ… åˆ—åä¸¥æ ¼åŒ¹é…ï¼š
           é—¨è¯Šæ—¥å¿—ï¼šå§“åã€èº«ä»½è¯ã€è¯Šæ–­ã€å°±è¯Šæ—¶é—´
           ç½‘æŠ¥å¡ï¼šæ‚£è€…å§“åã€æœ‰æ•ˆè¯ä»¶å·ã€ç–¾ç—…åç§°ã€æŠ¥å‘Šå¡å½•å…¥æ—¶é—´
        âœ… å®‰è£…ä¾èµ–æ—¶è‡ªåŠ¨ä½¿ç”¨æ¸…å/å—å¼€/é˜¿é‡Œæºï¼Œç½‘ç»œé—®é¢˜å¯æ‰‹åŠ¨åˆ‡æ¢æº
           - éƒ¨åˆ†ç½‘ç»œç¯å¢ƒå¯èƒ½è¢«æ‹¦æˆªï¼Œè‹¥æ— æ³•å®‰è£…ä¾èµ–å¯ä½¿ç”¨Wifiå°è¯•

        æŒ‰ä»»æ„é”®è¿”å›ä¸»èœå•...
        """
        print(doc)
        input("æŒ‰ä»»æ„é”®è¿”å›ä¸»èœå•...")


    def check_update():
        try:
            current_version = "20250417"
            response = requests.get(
                "https://api.github.com/repos/username/repo/releases/latest",
                timeout=3
            )
            latest_version = response.json()['tag_name']
            if latest_version > current_version:
                print(f"å‘ç°æ–°ç‰ˆæœ¬{latest_version}ï¼Œè¯·è®¿é—®é¡¹ç›®ä¸»é¡µä¸‹è½½æ›´æ–°")
        except Exception:
            pass


    check_update()
    files = {
        'é—¨è¯Šæ—¥å¿—': Path(sys.argv[0]).parent / 'åŒ»é™¢é—¨è¯Šæ—¥å¿—.csv',
        'ç½‘æŠ¥å¡': Path(sys.argv[0]).parent / 'å¤§ç–«æƒ…ç½‘æŠ¥å¡.csv',
        'åˆç­›ç»“æœ': Path(sys.argv[0]).parent / 'åŒ»é™¢é—¨è¯Šæ—¥å¿—ï¼ˆç­›é€‰åï¼‰.csv',
        'ç»“æœæ–‡æœ¬': Path(sys.argv[0]).parent / 'ç»“æœ.txt',
        'å·²æŠ¥å¡': Path(sys.argv[0]).parent / 'ç»“æœ(å·²æŠ¥å‘Šå¡).csv',
        'æ¼æŠ¥å¡': Path(sys.argv[0]).parent / 'ç»“æœ(å¯ç–‘æ¼æŠ¥å¡).csv',
        'é‡å¤æ¡ç›®': Path(sys.argv[0]).parent / 'ç»“æœï¼ˆå·²æŠ¥å‘Šå¡ï¼‰ä¸­é‡å¤æ¡ç›®.csv'
    }

    while True:
        try:
            step = input("""
                     ã€ä¼ æŸ“ç—…æŠ¥å¡åˆ†æç³»ç»Ÿã€‘
        versionï¼šV20250417       authorï¼šYueXiuCDC-LGY
        ***åŒ»ç–—æœºæ„å†…éƒ¨ä½¿ç”¨
        ***è‹¥æŠ¥é”™è¯·å…ˆæŸ¥çœ‹è¯´æ˜æ–‡æ¡£æ’æŸ¥
        =============================================================
        ä»…éœ€ä¿è¯æ–‡ä»¶æœ‰æ•ˆè¡¨å¤´åç§°ä¸¥æ ¼ä¸€è‡´å³å¯ä½¿ç”¨ï¼Œç®€å•æ˜“ç”¨
        - åŒ»é™¢é—¨è¯Šæ—¥å¿—.csv
        ï¼ˆå¿…é¡»åˆ—ï¼šå§“åã€èº«ä»½è¯ã€è¯Šæ–­ã€å°±è¯Šæ—¶é—´ï¼‰
        - å¤§ç–«æƒ…ç½‘æŠ¥å¡.csv
        ï¼ˆå¿…é¡»åˆ—ï¼šæ‚£è€…å§“åã€æœ‰æ•ˆè¯ä»¶å·ã€ç–¾ç—…åç§°ã€æŠ¥å‘Šå¡å½•å…¥æ—¶é—´ï¼‰
        =============================================================
        1. æ ¹æ®å­—æ®µåˆç­›é—¨è¯Šæ—¥å¿—æ•°æ®
        2. åˆ†ææŠ¥å¡åŠæ—¶æ€§ï¼ˆéœ€å…ˆå®Œæˆæ­¥éª¤1ï¼‰
        3. æŸ¥çœ‹è¯´æ˜æ–‡æ¡£
        4. é€€å‡ºç¨‹åº
        =============================================================
        è¾“å…¥æ­¥éª¤ï¼ˆ1/2/3/4ï¼‰: """).strip().lower()

            if step == '4':
                print("ç¨‹åºé€€å‡º...")
                break

            if step == '1':
                if not files['é—¨è¯Šæ—¥å¿—'].exists():
                    raise FileNotFoundError("æœªæ‰¾åˆ°ã€åŒ»é™¢é—¨è¯Šæ—¥å¿—.csvã€ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å")
                data = read_data(files['é—¨è¯Šæ—¥å¿—'])
                select_data(data, files['åˆç­›ç»“æœ'])

            elif step == '2':
                for file in [files['åˆç­›ç»“æœ'], files['ç½‘æŠ¥å¡']]:
                    if not file.exists():
                        raise FileNotFoundError(f"ç¼ºå°‘å¿…è¦æ–‡ä»¶ï¼š{file.name}")
                time_unit = input("""
        è¾“å…¥æ—¶é—´ç²¾åº¦ï¼ˆd=å¤©/h=å°æ—¶ï¼‰: """).strip().lower()
                while time_unit not in {'d', 'h'}:
                    time_unit = input("é”™è¯¯ï¼šè¯·è¾“å…¥ d æˆ– h: ").strip().lower()
                data_match = match_two_database(files['åˆç­›ç»“æœ'], files['ç½‘æŠ¥å¡'])
                if data_match is not None:
                    analysis(
                        data_match,
                        files['ç»“æœæ–‡æœ¬'],
                        files['å·²æŠ¥å¡'],
                        files['æ¼æŠ¥å¡'],
                        files['é‡å¤æ¡ç›®'],
                        time_unit
                    )

            elif step == '3':
                show_instructions()

            else:
                raise ValueError("è¯·è¾“å…¥æœ‰æ•ˆæ­¥éª¤ï¼ˆ1/2/3/4ï¼‰")

        except Exception as e:
            error_log = Path(sys.argv[0]).parent / 'error_log.txt'
            with open(error_log, 'a', encoding='utf-8') as f:
                f.write(f"{datetime.now()}\n")
                f.write(traceback.format_exc())
            print(f"é”™è¯¯è¯¦æƒ…å·²è®°å½•è‡³ï¼š{error_log.resolve()}")
            print(f"\n{'=' * 50}")
            print(f"âŒ ç¨‹åºå¼‚å¸¸ï¼š{str(e)}")
            traceback.print_exc()
            print(f"{'=' * 50}")
            print("æ’æŸ¥å»ºè®®ï¼š\n1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”åˆ—åæ­£ç¡®\n2. ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD\n3. æ‰‹åŠ¨å®‰è£…ç¼ºå¤±åº“ï¼špip install pandas chardet tqdm python-dateutil requests")

    if sys.platform.startswith('win'):
        input("\næŒ‰ä»»æ„é”®é€€å‡ºç¨‹åº...")
    